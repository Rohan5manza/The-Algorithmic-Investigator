Unveiling the wizardry of ChatGPT

ROHAN MARAR
MAY 20, 2023

We all know that by now, ChatGPT has taken the world by storm. Since its release, it has been used in numerous applications, and has made many tasks a lot easier for humans in various domains. People have even remarked at the way it seems almost magical, or appears to exhibit "real" human-like intelligence, along with creativity. Can we really say it is truly intelligent ? What does being "intelligent" even mean ? Does everyone understand how it really works under-the-hood? To know more, read on !

ChatGPT is an artificial intelligence chatbot that uses natural language processing to create human-like conversational dialogue. OpenAI is the company that created and released this AI. It is a form of generative AI that can generate text. It is a language model based on GPT-3.5, developed by OpenAI. GPT stands for "Generative Pre-trained Transformer".

What is "generative" AI? It means that the AI can generate, or create, new outputs in form of text, images, or even videos, based on certain inputs. This is significantly different from other types of AI. For example, the AI used to teach a robot how to walk, uses a radically different type of AI called reinforcement learning, that improves the robot's perception by giving it rewards if it does something correct, and penalties if it does something wrong. Large Language models(LLMs) like ChatGPT on the other hand, use deep learning.

A language model is an AI model that can understand and generate natural language. It is designed to predict the likelihood of a sequence of words in a language. For example, given the sentence "I am going to the __", a language model should be able to predict the next word in the sentence, which is likely to be "store" or "park" depending on the context. It uses deep learning methods, in which neural networks are used.

A short detour to machine learning and deep learning:

Language models are trained on large datasets of text and use statistical methods to learn the patterns and relationships between words in the language. Such statistical methods are employed with the help of machine learning, a type of AI that requires a lot of data to find complex patterns between that given data, in order to predict a new entity. Machine learning is based on powerful mathematical functions that make artificial neurons a reality. For ChatGPT, the next probable word in a given sentence is predicted.

Deep learning is a subset of machine learning that involves training algorithms to recognize patterns in data. Neural networks are a type of deep learning algorithm that are modeled after the structure of the human brain. They consist of layers of interconnected nodes that process information and make predictions based on that information. By training a neural network on a large dataset, it can learn to recognize patterns in the data and make predictions with a high degree of accuracy.

Let's delve in deeper to understand how ChatGPT really works.

ChatGPT uses a transformer architecture. The transformer architecture was introduced by Google in 2017, and has since become state-of-the-art for many natural language processing tasks.

The transformer architecture is designed to process sequences of input data, such as words in a sentence, and make predictions based on the context of the sequence. This is achieved through a process called attention, which allows the model to focus on the most relevant parts of the input sequence. The GPT architecture is trained on large amounts of text data to learn the patterns and relationships between words in the language.

"Attention is all you need" was the name of the research paper that first introduced the term transformer. Hence , "attention" is the key concept behind ChatGPT.

No alt text provided for this image
In order to understand the context and priority of words sequence-by-sequence, ChatGPT represents the words in certain ways as shown.
ChatGPT works by processing sequences of text data, such as words in a sentence, and generating new text based on the patterns and relationships it has learned from the training data. The model consists of multiple layers of neural networks that transform the input data and generate output data.

The input data is processed through a series of layers called the encoder, which transforms the input data into a set of features that capture the patterns and relationships between the words in the sequence. The encoder uses self-attention to focus on the most relevant parts of the input sequence and learns to represent the input data in a high-dimensional space. In the below image, we can see how each word is now represented in form of an array of numbers, called vectors, that can be easily understood by the AI model , and that helps to track patterns in data.

No alt text provided for this image
The output data is generated by a series of layers called the decoder, which takes the features learned by the encoder and generates new text based on the context of the input sequence. The decoder uses self-attention to generate text that is coherent and relevant to the input sequence. This tells us why prompting is really important, as the answers that ChatGPT generates changes directly to how the input was phrased. Its importance is so much that by now, people have created something called "prompt engineering"!

No alt text provided for this image
The ChatGPT model is pre-trained on large amounts of text data, such as Wikipedia articles, news articles, and books. This pre-training allows the model to learn the patterns and relationships between words in the language and generate coherent and relevant text based on the input sequence.

Also, remember how I mentioned reinforcement learning(RL) earlier? Turns out that, in order to improve the model based on user feedback, ChatGPT does use RL to make its next answers better, via the "like" or "dislike" button that appears after ChatGPT generates an answer for us!

GPUs as the saviors

Training a language model like Chat GPT requires a large amount of computational resources, such as memory and processing power. This is because the model needs to process large amounts of data and perform complex mathematical operations. To perform these operations efficiently, GPUs, or Graphics Processing Units, are used instead of traditional CPUs, or Central Processing Units. GPUs are specialized hardware that are designed to handle large amounts of parallel computation, making them ideal for training deep learning models like Chat GPT.

The parallel architecture of GPUs allows them to perform thousands of mathematical operations simultaneously, speeding up the training process significantly. GPUs are also designed to handle the large amounts of memory required for deep learning models, allowing them to store and process large amounts of data efficiently. All of this is further facilitated by the advent of cloud computing.

Final Thoughts

Alan Turing once designed something called a "Turing test". This is a test aimed to check whether a machine exhibits intelligent behaviour equivalent to, or indistinguishable from, that of a human. It is an efficient method of checking the power of ChatGPT. It is clear to many people that ChatGPT passes the test in some regards, but also fails the test in many other aspects.

In the case of ChatGPT, it is evident that it is not "truly" intelligent. It is decidedly not conscious, and has no power of imagination. While it may appear to us that it exhibits true creativity, it is not so. The "creativity" it demonstrates is the result of powerful machine learning algorithms that can efficiently predict the next word in the sentence. In other words, its something that really clever when it comes to answering , but does not truly understand the meaning of the words it generates. It cannot fundamentally understand the meaning of a word, only its priority or likelihood. Thus, a clever veil of "intelligence" is created which makes us feel scared, to the point that nowadays programmers feel that their job is at a risk!
